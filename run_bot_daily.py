import torch
import torch.nn as nn
import pandas as pd
import numpy as np
import ephem  # Th∆∞ vi·ªán t√≠nh sao x·ªãn s√≤
import datetime
import os
import schedule
import time
import requests
from bs4 import BeautifulSoup
from datetime import timedelta

# =============================================================================
# 1. C·∫§U H√åNH H·ªÜ TH·ªêNG (CONFIG)
# =============================================================================
MODEL_PATH = 'model_lb90_seed44_BEST.pth'  # ƒê∆∞·ªùng d·∫´n model x·ªãn nh·∫•t c·ªßa ƒë·∫°i ca
DATA_FILE = 'du_lieu_chiem_tinh_chuan_gio.parquet'
LOOKBACK_DAYS = 90
NUM_CLASSES = 100
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# T·ªça ƒë·ªô H√† N·ªôi (ƒë·ªÉ t√≠nh sao cho chu·∫©n gi·ªù quay)
LATITUDE = '21.0285'
LONGITUDE = '105.8542'

print(f"üîÆ KH·ªûI ƒê·ªòNG BOT TH·∫¶N C∆† DI·ªÜU TO√ÅN TR√äN: {DEVICE}")

# =============================================================================
# 2. KI·∫æN TR√öC MODEL (PH·∫¢I GI·ªêNG H·ªÜT FILE TRAIN)
# =============================================================================
# Copy nguy√™n xi t·ª´ file train c·ªßa ƒë·∫°i ca ƒë·ªÉ load ƒë∆∞·ª£c tr·ªçng s·ªë

class GatedResidualNetwork(nn.Module):
    def __init__(self, input_size, hidden_size, dropout=0.3):
        super(GatedResidualNetwork, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.elu = nn.ELU()
        self.fc2 = nn.Linear(hidden_size, hidden_size)
        self.dropout = nn.Dropout(dropout)
        self.gate = nn.Linear(input_size, hidden_size)
        self.norm = nn.LayerNorm(hidden_size)
        
        if input_size != hidden_size:
            self.project = nn.Linear(input_size, hidden_size)
        else:
            self.project = None

    def forward(self, x):
        residual = self.project(x) if self.project is not None else x
        x_val = self.fc1(x)
        x_val = self.elu(x_val)
        x_val = self.fc2(x_val)
        x_val = self.dropout(x_val)
        gate_val = torch.sigmoid(self.gate(x))
        out = (x_val * gate_val) + residual
        return self.norm(out)

class UltimateAstroModel(nn.Module):
    def __init__(self, num_classes, lookback_days, astro_features, d_model=64, nhead=4):
        super(UltimateAstroModel, self).__init__()
        self.hist_proj = nn.Linear(num_classes, d_model)
        self.pos_embedding = nn.Parameter(torch.randn(1, lookback_days, d_model))
        self.hist_gate = GatedResidualNetwork(d_model, d_model)
        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, batch_first=True, dropout=0.1)
        self.hist_encoder = nn.TransformerEncoder(encoder_layer, num_layers=2)
        self.astro_gate = GatedResidualNetwork(astro_features, d_model)
        self.cross_attention = nn.MultiheadAttention(embed_dim=d_model, num_heads=nhead, batch_first=True)
        self.norm_cross = nn.LayerNorm(d_model)
        self.fusion_gate = GatedResidualNetwork(d_model * 2, 128)
        self.final_out = nn.Linear(128, num_classes)

    def forward(self, x_hist, x_astro):
        h = self.hist_proj(x_hist) + self.pos_embedding
        h = self.hist_gate(h)
        h = self.hist_encoder(h)
        a = self.astro_gate(x_astro)
        a_query = a.unsqueeze(1)
        attn_out, _ = self.cross_attention(query=a_query, key=h, value=h)
        attn_out = self.norm_cross(attn_out + a_query)
        a_squeezed = a_query.squeeze(1)
        attn_squeezed = attn_out.squeeze(1)
        combined = torch.cat((a_squeezed, attn_squeezed), dim=1)
        return self.final_out(self.fusion_gate(combined))

# =============================================================================
# 3. C√ÅC H√ÄM X·ª¨ L√ù D·ªÆ LI·ªÜU & C√ÄO K·∫æT QU·∫¢ (SCRAPING)
# =============================================================================

def get_astro_features(date_str, columns_template):
    """
    T√≠nh v·ªã tr√≠ c√°c sao v√†o 18:30 c·ªßa ng√†y d·ª± b√°o.
    D√πng th∆∞ vi·ªán Ephem ƒë·ªÉ t√≠nh to√°n chu·∫©n x√°c.
    """
    obs = ephem.Observer()
    obs.lat = LATITUDE
    obs.lon = LONGITUDE
    # Gi·ªù quay s·ªë l√† 18:30
    obs.date = f"{date_str} 11:30:00" # Ephem d√πng gi·ªù UTC, VN l√† UTC+7 n√™n tr·ª´ ƒëi 7

    # Danh s√°ch c√°c h√†nh tinh c∆° b·∫£n (ƒê·∫°i ca c√≥ th·ªÉ th√™m n·∫øu file c≈© c√≥ nhi·ªÅu h∆°n)
    planets = {
        'Sun': ephem.Sun(obs),
        'Moon': ephem.Moon(obs),
        'Mercury': ephem.Mercury(obs),
        'Venus': ephem.Venus(obs),
        'Mars': ephem.Mars(obs),
        'Jupiter': ephem.Jupiter(obs),
        'Saturn': ephem.Saturn(obs),
        'Uranus': ephem.Uranus(obs),
        'Neptune': ephem.Neptune(obs)
    }

    # T·∫°o dictionary d·ªØ li·ªáu
    data_dict = {}
    for name, body in planets.items():
        # L·∫•y kinh ƒë·ªô ho√†ng ƒë·∫°o (Ecliptic Longitude) - Quy ra ƒë·ªô (0-360)
        lon = np.degrees(body.hlon)
        data_dict[name] = lon

    # Mapping v√†o vector ƒë√∫ng theo th·ª© t·ª± c·ªôt c·ªßa file Parquet c≈©
    # L∆∞u √Ω: H√†m n√†y gi·∫£ ƒë·ªãnh t√™n c·ªôt trong file Parquet l√† t√™n h√†nh tinh (v√≠ d·ª• 'Sun', 'Moon'...)
    # N·∫øu file ƒë·∫°i ca d√πng t√™n kh√°c (v√≠ d·ª• 'Sun_Deg'), code s·∫Ω t·ª± kh·ªõp n·∫øu t√™n ch·ª©a t·ª´ kh√≥a.
    
    feature_vector = []
    for col in columns_template:
        val = 0.0
        found = False
        for p_name, p_val in data_dict.items():
            if p_name in col: # So s√°nh kh·ªõp t√™n
                val = p_val
                found = True
                break
        feature_vector.append(val)
    
    return np.array(feature_vector, dtype='float32')

def fetch_xskt_results(date_str):
    """
    H√†m c√†o d·ªØ li·ªáu x·ªï s·ªë mi·ªÅn B·∫Øc cho ng√†y date_str (format YYYY-MM-DD).
    Tr·∫£ v·ªÅ list c√°c s·ªë ƒë√£ v·ªÅ.
    """
    # Convert YYYY-MM-DD -> DD-MM-YYYY ƒë·ªÉ request web
    d = datetime.datetime.strptime(date_str, '%Y-%m-%d')
    fmt_date = d.strftime('%d-%m-%Y')
    
    url = f"https://xoso.com.vn/xsmb-{fmt_date}.html"
    try:
        response = requests.get(url, timeout=10)
        if response.status_code != 200:
            return None
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Logic l·∫•y gi·∫£i ƒêB -> Gi·∫£i 7 (T√πy trang web, ƒë√¢y l√† logic ph·ªï th√¥ng)
        # T√¨m t·∫•t c·∫£ th·∫ª span c√≥ class l√† s·ªë k·∫øt qu·∫£ (th∆∞·ªùng class ch·ª©a 'v-g')
        # ƒê√¢y l√† v√≠ d·ª• logic c√†o, ƒë·∫°i ca c·∫ßn check l·∫°i c·∫•u tr√∫c trang n·∫øu web ƒë·ªïi source
        numbers = []
        
        # C√°ch l·∫•y ƒë∆°n gi·∫£n: t√¨m t·∫•t c·∫£ c√°c th·∫ª ch·ª©a s·ªë (th∆∞·ªùng n·∫±m trong table)
        tables = soup.find_all('table', class_='table-result')
        if not tables:
            return None
            
        for table in tables:
            spans = table.find_all('span')
            for s in spans:
                txt = s.get_text().strip()
                if txt.isdigit():
                    # L·∫•y 2 s·ªë cu·ªëi
                    tail = txt[-2:]
                    numbers.append(int(tail))
        
        return list(set(numbers)) # Tr·∫£ v·ªÅ danh s√°ch c√°c s·ªë unique (0-99)
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói c√†o d·ªØ li·ªáu ng√†y {date_str}: {e}")
        return None

def update_dataset():
    """
    Ki·ªÉm tra file Parquet, n·∫øu thi·∫øu ng√†y th√¨ t·ª± ƒë·ªông c√†o th√™m v√† update file.
    """
    print("üîÑ ƒêang ki·ªÉm tra v√† c·∫≠p nh·∫≠t d·ªØ li·ªáu...")
    if not os.path.exists(DATA_FILE):
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y file {DATA_FILE}. Kh√¥ng th·ªÉ ch·∫°y.")
        return None, None

    df = pd.read_parquet(DATA_FILE)
    df['Date'] = pd.to_datetime(df['Date'])
    last_date = df['Date'].max().date()
    today = datetime.date.today()
    
    # X√°c ƒë·ªãnh c√°c c·ªôt chi√™m tinh (ƒë·ªÉ ƒëi·ªÅn d·ªØ li·ªáu m·ªõi)
    res_cols = [c for c in df.columns if c.startswith('Res_')]
    astro_cols = [c for c in df.columns if c not in res_cols and c != 'Date' and not c.endswith('_Deg')]
    
    if last_date >= today - timedelta(days=1):
        print("‚úÖ D·ªØ li·ªáu ƒë√£ c·∫≠p nh·∫≠t ƒë·∫øn h√¥m qua. S·∫µn s√†ng d·ª± b√°o!")
        return df, astro_cols

    # N·∫øu thi·∫øu d·ªØ li·ªáu, ch·∫°y v√≤ng l·∫∑p update
    current_date = last_date + timedelta(days=1)
    new_rows = []
    
    while current_date < today: # Ch·ªâ update ƒë·∫øn h√¥m qua (v√¨ h√¥m nay ch∆∞a x·ªï)
        str_date = current_date.strftime('%Y-%m-%d')
        print(f"   >> ƒêang c√†o d·ªØ li·ªáu ng√†y {str_date}...")
        
        results = fetch_xskt_results(str_date)
        if results:
            # T·∫°o row m·ªõi
            row = {'Date': pd.Timestamp(current_date)}
            # ƒêi·ªÅn Astro
            astro_vals = get_astro_features(str_date, astro_cols)
            for i, col in enumerate(astro_cols):
                row[col] = astro_vals[i]
            
            # ƒêi·ªÅn K·∫øt qu·∫£ (Res_0 ... Res_XX) - L∆∞u √Ω file c≈© ƒë·∫°i ca l∆∞u ki·ªÉu g√¨
            # Gi·∫£ s·ª≠ file c≈© l∆∞u danh s√°ch c√°c s·ªë v·ªÅ. ·ªû ƒë√¢y em fill NaN tr∆∞·ªõc
            for col in res_cols:
                row[col] = np.nan
            
            # Fill k·∫øt qu·∫£ th·ª±c t·∫ø
            for i, num in enumerate(results):
                if i < len(res_cols):
                    row[f'Res_{i}'] = float(num)
            
            new_rows.append(row)
            print(f"      -> ƒê√£ th√™m {len(results)} s·ªë.")
        else:
            print(f"      -> Kh√¥ng c√≥ d·ªØ li·ªáu ho·∫∑c web l·ªói.")
        
        current_date += timedelta(days=1)

    if new_rows:
        new_df = pd.DataFrame(new_rows)
        df = pd.concat([df, new_df], ignore_index=True)
        # L∆∞u ƒë√® file c≈©
        df.to_parquet(DATA_FILE)
        print(f"üíæ ƒê√£ c·∫≠p nh·∫≠t th√™m {len(new_rows)} ng√†y v√†o Data.")
    
    return df, astro_cols

# =============================================================================
# 4. H√ÄM D·ª∞ B√ÅO (INFERENCE)
# =============================================================================

def predict_today():
    print(f"\n{'='*60}")
    print(f"üé≤ B·∫ÆT ƒê·∫¶U PHI√äN D·ª∞ B√ÅO NG√ÄY {datetime.date.today()}")
    print(f"{'='*60}")
    
    # 1. Update v√† Load d·ªØ li·ªáu
    df, astro_cols = update_dataset()
    if df is None: return

    # 2. Chu·∫©n b·ªã Input L·ªãch s·ª≠ (Last 90 days)
    # C·∫ßn l·∫•y 90 ng√†y c√≥ d·ªØ li·ªáu x·ªï s·ªë g·∫ßn nh·∫•t
    # Logic: L·ªçc nh·ªØng ng√†y c√≥ k·∫øt qu·∫£ kh√¥ng null
    res_cols = [c for c in df.columns if c.startswith('Res_')]
    
    # Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu sang vector 100 chi·ªÅu
    # Ch·ªâ l·∫•y nh·ªØng d√≤ng c√≥ d·ªØ li·ªáu x·ªï s·ªë ƒë·ªÉ l√†m History
    valid_rows = df.dropna(subset=[res_cols[0]]) # Gi·∫£ s·ª≠ c·ªôt Res_0 ph·∫£i c√≥
    
    if len(valid_rows) < LOOKBACK_DAYS:
        print("‚ùå Kh√¥ng ƒë·ªß d·ªØ li·ªáu l·ªãch s·ª≠ (c·∫ßn √≠t nh·∫•t 90 ng√†y).")
        return

    # L·∫•y 90 ng√†y cu·ªëi c√πng
    last_90_days = valid_rows.iloc[-LOOKBACK_DAYS:]
    raw_results = last_90_days[res_cols].values
    
    x_hist = np.zeros((1, LOOKBACK_DAYS, NUM_CLASSES), dtype='float32')
    
    for t in range(LOOKBACK_DAYS):
        day_res = raw_results[t]
        for num in day_res:
            if pd.notna(num):
                idx = int(num)
                if 0 <= idx <= 99:
                    x_hist[0, t, idx] = 1.0
    
    # 3. Chu·∫©n b·ªã Input Chi√™m tinh (H√îM NAY - T∆Ø∆†NG LAI)
    today_str = datetime.date.today().strftime('%Y-%m-%d')
    astro_vals = get_astro_features(today_str, astro_cols)
    x_astro = torch.tensor(astro_vals, dtype=torch.float32).unsqueeze(0) # (1, num_features)
    x_hist = torch.tensor(x_hist, dtype=torch.float32)

    # 4. Load Model
    # C·∫ßn x√°c ƒë·ªãnh num_features t·ª´ file d·ªØ li·ªáu ƒë·ªÉ init model
    num_astro_features = len(astro_cols)
    
    model = UltimateAstroModel(NUM_CLASSES, LOOKBACK_DAYS, num_astro_features).to(DEVICE)
    
    if os.path.exists(MODEL_PATH):
        # L∆∞u √Ω: C·∫ßn th√™m weights_only=False n·∫øu torch b√°o l·ªói
        try:
            checkpoint = torch.load(MODEL_PATH, map_location=DEVICE, weights_only=False)
        except:
             checkpoint = torch.load(MODEL_PATH, map_location=DEVICE)
             
        # Checkpoint c·ªßa ƒë·∫°i ca l∆∞u c·∫£ optimizer, n√™n ph·∫£i tr·ªçc v√†o l·∫•y state_dict c·ªßa model th√¥i
        if 'model_state_dict' in checkpoint:
            model.load_state_dict(checkpoint['model_state_dict'])
        else:
            model.load_state_dict(checkpoint) # Tr∆∞·ªùng h·ª£p file ch·ªâ l∆∞u weight
            
        model.eval()
        print("ü§ñ Model ƒë√£ load th√†nh c√¥ng! ƒêang soi c·∫ßu...")
    else:
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y model {MODEL_PATH}")
        return

    # 5. Predict
    with torch.no_grad():
        x_hist = x_hist.to(DEVICE)
        x_astro = x_astro.to(DEVICE)
        
        output = model(x_hist, x_astro)
        # Output l√† Logits, qua Sigmoid ƒë·ªÉ ra x√°c su·∫•t
        probs = torch.sigmoid(output).squeeze(0) # (100,)
        
    # 6. L·∫•y Top 5
    top5_prob, top5_idx = torch.topk(probs, 5)
    
    top5_numbers = top5_idx.cpu().numpy()
    top5_percent = top5_prob.cpu().numpy() * 100
    
    print("\n" + "*"*40)
    print(f"üåü K·∫æT QU·∫¢ D·ª∞ B√ÅO NG√ÄY {today_str} üåü")
    print("*"*40)
    for i in range(5):
        print(f"   üèÜ TOP {i+1}: S·ªë {top5_numbers[i]:02d} (T·ªâ l·ªá: {top5_percent[i]:.2f}%)")
    print("*"*40)
    print("üëâ ƒê·∫°i ca tham kh·∫£o, ch√∫c ƒë·∫°i ca may m·∫Øn!\n")

# =============================================================================
# 5. MAIN LOOP (CH·∫†Y H·∫∞NG NG√ÄY)
# =============================================================================

def job():
    print(f"\n‚è∞ ƒê√£ ƒë·∫øn gi·ªù G (Time check: {datetime.datetime.now()})")
    predict_today()

if __name__ == "__main__":
    # Test ch·∫°y ngay l·∫ßn ƒë·∫ßu ti√™n khi m·ªü tool
    predict_today()
    
    # H·∫πn gi·ªù ch·∫°y h·∫±ng ng√†y v√†o l√∫c 16:30 (4h30 chi·ªÅu)
    # ƒê·ªÉ c√≥ th·ªùi gian nghi√™n c·ª©u tr∆∞·ªõc gi·ªù quay
    schedule.every().day.at("16:30").do(job)
    
    print("üí§ Bot ƒëang chuy·ªÉn sang ch·∫ø ƒë·ªô ng·ªß ƒë√¥ng. Ch·ªù ƒë·∫øn 16:30 h·∫±ng ng√†y s·∫Ω t·ª± d·∫≠y l√†m vi·ªác...")
    
    while True:
        schedule.run_pending()
        time.sleep(60) # Ng·ªß 1 ph√∫t check 1 l·∫ßn